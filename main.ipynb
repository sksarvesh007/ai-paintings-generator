{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":36285,"sourceType":"datasetVersion","datasetId":28335},{"sourceId":211501,"sourceType":"datasetVersion","datasetId":91257},{"sourceId":310927,"sourceType":"datasetVersion","datasetId":130081},{"sourceId":1044068,"sourceType":"datasetVersion","datasetId":576756},{"sourceId":1113486,"sourceType":"datasetVersion","datasetId":494022},{"sourceId":1833183,"sourceType":"datasetVersion","datasetId":1089650},{"sourceId":2066194,"sourceType":"datasetVersion","datasetId":1238394},{"sourceId":3043131,"sourceType":"datasetVersion","datasetId":1863655},{"sourceId":3433776,"sourceType":"datasetVersion","datasetId":1177156},{"sourceId":3813986,"sourceType":"datasetVersion","datasetId":2252882},{"sourceId":4840773,"sourceType":"datasetVersion","datasetId":2805433},{"sourceId":5303434,"sourceType":"datasetVersion","datasetId":3083270}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:06:50.476179Z","iopub.execute_input":"2024-05-19T15:06:50.476850Z","iopub.status.idle":"2024-05-19T15:07:15.001266Z","shell.execute_reply.started":"2024-05-19T15:06:50.476820Z","shell.execute_reply":"2024-05-19T15:07:15.000246Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-19 15:06:59.064150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-19 15:06:59.064256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-19 15:06:59.197016: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bee0cbb4f9b34e6397bf4677cb99349b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e8580cb8f5949fb90f6b8c8ebc5672c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf3f52a9b714218838119857ed802cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8334c0bd46084b549726489d4a7dccc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c216e4eedbb458b8dee981b0b806c14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2450d73cadf4b948815ca481f50e660"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c8fc55a9fc14028acdd1f7b8a43a803"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\n\n# List of base directories\nbase_directories = [\n    '/kaggle/input/segmented-bob-ross-images',\n    '/kaggle/input/paintings-0',\n    '/kaggle/input/d',\n    '/kaggle/input/edvard-munch-paintings',\n    '/kaggle/input/nativity-paintings-dataset',\n    '/kaggle/input/abstract-paintings-dataset',\n    '/kaggle/input/impressionistlandscapespaintings',\n    '/kaggle/input/art-images-drawings-painting-sculpture-engraving',\n    '/kaggle/input/oil-painting-images',\n    '/kaggle/input/cyclegan-oilpainting-dataset'\n]\n\n# Target directory where all images will be moved\ntarget_directory = '/kaggle/working/collected_images'\nif not os.path.exists(target_directory):\n    os.makedirs(target_directory)\n\ndef move_images_to_target(base_dir, target_dir):\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):\n                src_path = os.path.join(root, file)\n                dest_path = os.path.join(target_dir, file)\n                if os.path.exists(dest_path):\n                    base, extension = os.path.splitext(file)\n                    counter = 1\n                    new_dest_path = os.path.join(target_dir, f\"{base}_{counter}{extension}\")\n                    while os.path.exists(new_dest_path):\n                        counter += 1\n                        new_dest_path = os.path.join(target_dir, f\"{base}_{counter}{extension}\")\n                    dest_path = new_dest_path\n                \n                shutil.copy2(src_path, dest_path)\n\nfor base_directory in base_directories:\n    print(base_directory)\n    move_images_to_target(base_directory, target_directory)\n\nprint(\"Completed moving all images.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:07:15.003547Z","iopub.execute_input":"2024-05-19T15:07:15.004273Z","iopub.status.idle":"2024-05-19T15:15:41.615710Z","shell.execute_reply.started":"2024-05-19T15:07:15.004239Z","shell.execute_reply":"2024-05-19T15:15:41.614771Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/segmented-bob-ross-images\n/kaggle/input/paintings-0\n/kaggle/input/d\n/kaggle/input/edvard-munch-paintings\n/kaggle/input/nativity-paintings-dataset\n/kaggle/input/abstract-paintings-dataset\n/kaggle/input/impressionistlandscapespaintings\n/kaggle/input/art-images-drawings-painting-sculpture-engraving\n/kaggle/input/oil-painting-images\n/kaggle/input/cyclegan-oilpainting-dataset\nCompleted moving all images.\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimage_files = [name for name in os.listdir(target_directory) if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\ntotal_images = len(image_files)\nnum_images_to_remove = total_images // 10\nimages_to_remove = random.sample(image_files, num_images_to_remove)\nfor image in images_to_remove:\n    os.remove(os.path.join(target_directory, image))\nupdated_total_images = len([name for name in os.listdir(target_directory) if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))])\nprint(f'Total number of images in {target_directory} after removal: {updated_total_images}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:15:41.616949Z","iopub.execute_input":"2024-05-19T15:15:41.617330Z","iopub.status.idle":"2024-05-19T15:15:42.385725Z","shell.execute_reply.started":"2024-05-19T15:15:41.617298Z","shell.execute_reply":"2024-05-19T15:15:42.384590Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total number of images in /kaggle/working/collected_images after removal: 112462\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:21:59.256912Z","iopub.execute_input":"2024-05-19T15:21:59.257304Z","iopub.status.idle":"2024-05-19T15:21:59.261704Z","shell.execute_reply.started":"2024-05-19T15:21:59.257275Z","shell.execute_reply":"2024-05-19T15:21:59.260683Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nfolder_path = '/kaggle/working/collected_images'\n\n# List all image files in the folder\nall_images = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.png'))]\n\n# Batch size\nbatch_size = 100\n\n# Process images in batches\nfor i in range(0, len(all_images), batch_size):\n    print(i)\n    batch_images = all_images[i:i + batch_size]\n    image_data = []\n\n    # Process each image in the batch\n    for filename in batch_images:\n        img_path = os.path.join(folder_path, filename)\n        \n        try:\n            raw_image = Image.open(img_path).convert('RGB')\n        except UnidentifiedImageError:\n            print(f'Skipping file {filename} as it is not a valid image.')\n            continue\n\n        # Conditional image captioning\n        text = \"a photography of\"\n        inputs = processor(raw_image, text, return_tensors=\"pt\")\n\n        # Unconditional image captioning\n        inputs = processor(raw_image, return_tensors=\"pt\")\n\n        out = model.generate(**inputs)\n        description = processor.decode(out[0], skip_special_tokens=True)\n        \n\n        # Append the image ID and description to the list\n        image_data.append({\"image_id\": filename, \"description\": description})\n\n    # Specify the CSV file path for the current batch\n    csv_file_path = f'/kaggle/working/image_descriptions_batch_{i//batch_size + 1}.csv'\n\n    # Write the image data to the CSV file\n    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n        writer = csv.DictWriter(file, fieldnames=[\"image_id\", \"description\"])\n        writer.writeheader()\n        writer.writerows(image_data)\n\n    print(f'Descriptions for batch {i//batch_size + 1} saved to {csv_file_path}')\n\nprint(\"Completed processing all images.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:22:23.706617Z","iopub.execute_input":"2024-05-19T15:22:23.706962Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0\nDescriptions for batch 1 saved to /kaggle/working/image_descriptions_batch_1.csv\n100\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}